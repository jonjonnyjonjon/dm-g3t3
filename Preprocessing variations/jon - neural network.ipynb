{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51dca08",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9681e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonw/miniforge3/envs/ml_env/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0-rc0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, fbeta_score, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.autograph.set_verbosity(0)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Recall, AUC, Precision\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dcbfbd",
   "metadata": {},
   "source": [
    "# Reading file and tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b973afe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"../dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede055de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[\"risk_flag\"]\n",
    "x_train = df_train.drop(\"risk_flag\", axis=1)\n",
    "\n",
    "y_test = df_test[\"risk_flag\"]\n",
    "x_test = df_test.drop(\"risk_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae907b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonw/miniforge3/envs/ml_env/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "def target_encoding(df_x, df_y):\n",
    "    x = df_x.copy()\n",
    "    \n",
    "    # Target Encoding â€” categorical columns with high cardinality: profession, city, state\n",
    "    profession_target_enc = TargetEncoder()\n",
    "    x[\"profession_encoded\"] = profession_target_enc.fit_transform(x[\"profession\"], df_y)\n",
    "    \n",
    "    city_target_enc = TargetEncoder()\n",
    "    x[\"city_encoded\"] = city_target_enc.fit_transform(x[\"city\"], df_y)\n",
    "    \n",
    "    state_target_enc = TargetEncoder()\n",
    "    x[\"state_encoded\"] = state_target_enc.fit_transform(x[\"state\"], df_y)\n",
    "    \n",
    "    x.drop(\"profession\", axis=1, inplace=True)\n",
    "    x.drop(\"city\", axis=1, inplace=True)\n",
    "    x.drop(\"state\", axis=1, inplace=True)\n",
    "    return x\n",
    "\n",
    "x_train = target_encoding(x_train, y_train)\n",
    "x_test = target_encoding(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f8da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x28f5eb160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-06 16:02:09.306422: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-06 16:02:09.306548: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x293033af0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1575/1575 [==============================] - 1s 535us/step - loss: 0.5153 - recall: 0.7531 - precision: 0.7531 - fbeta_score: 0.6031 - accuracy: 0.7531 - auc: 0.8273\n",
      "\n",
      "-----------------------TEST SCORES-----------------------\n",
      "Loss: 0.5153264403343201\n",
      "Recall: 0.7531150579452515\n",
      "Precision: 0.7531150579452515\n",
      "F2-Score: 0.8149861097335815\n",
      "Accuracy score: 0.7531150579452515\n",
      "AUC Score: 0.8273217082023621\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train[['income','age','experience']] = scaler.fit_transform(x_train[['income','age','experience']])\n",
    "x_test[['income','age','experience']] = scaler.fit_transform(x_test[['income','age','experience']])\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "oversampler = SMOTE(random_state=2021)\n",
    "x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "\n",
    "input_shape = (9,)\n",
    "\n",
    "# Changes shape to 3D\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)    \n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(120, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Configure the model and start training\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=[Recall(), Precision(), tfa.metrics.FBetaScore(num_classes=2, beta=2.0), 'accuracy', AUC()])\n",
    "model_fit = model.fit(x_train, y_train, epochs=5, batch_size=64, verbose=0, validation_split=0.2)\n",
    "test_results = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print()\n",
    "print(f\"-----------------------TEST SCORES-----------------------\")\n",
    "print(f\"Loss: {test_results[0]}\")\n",
    "print(f\"Recall: {test_results[1]}\")\n",
    "print(f\"Precision: {test_results[2]}\")\n",
    "print(f\"F2-Score: {test_results[3][0]}\")\n",
    "print(f\"Accuracy score: {test_results[4]}\")\n",
    "print(f\"AUC Score: {test_results[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d778c20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5153264403343201,\n",
       " 0.7531150579452515,\n",
       " 0.7531150579452515,\n",
       " array([0.8149861 , 0.39130434], dtype=float32),\n",
       " 0.7531150579452515,\n",
       " 0.8273217082023621]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fab126",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5z/tmp48bwn5lx0cw1mmf31bzgm0000gn/T/ipykernel_27570/1802790903.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "# recall = make_scorer(recall_score, average=\"macro\")\n",
    "# f1 = make_scorer(f1_score , average='macro')\n",
    "\n",
    "# def create_model(optimizer='adam', activation='relu'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(45, input_shape=(46,), activation=activation))\n",
    "#     model.add(Dense(25, activation='relu'))\n",
    "#     model.add(Dense(12, activation='relu'))\n",
    "#     model.add(Dense(6, activation='relu'))\n",
    "#     model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', Recall()])\n",
    "#     model.compile(loss='binary_crossentropy', \n",
    "#                   optimizer='adam', \n",
    "#                   metrics=[Recall(), tfa.metrics.FBetaScore(num_classes=2, beta=2.0), AUC()])\n",
    "#     return model\n",
    "\n",
    "# # fix random seed for reproducibility\n",
    "# seed = 0\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# # create model\n",
    "# model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# # define the grid search parameters\n",
    "# epochs = [30, 50, 100]\n",
    "# batch_size = [50, 100, 200, 250, 300, 350, 400]\n",
    "# optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "\n",
    "# param_grid = dict(epochs=epochs, optimizer=optimizer, batch_size=batch_size, activation=activation)\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "\n",
    "# grid_result = grid.fit(X_smote_train_scaled, y_smote_train_copy)\n",
    "\n",
    "# # summarize results\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
