{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading file and tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"loanprediction.csv\")\n",
    "df.drop(\"Id\", axis=1, inplace=True)\n",
    "df.columns = [\"income\", \"age\", \"experience\", \"marital_status\", \"house_ownership\", \"car_ownership\", \"profession\", \"city\", \"state\", \"current_job_years\", \"current_house_years\", \"risk_flag\"]\n",
    "numerical_cols = [\"income\", \"age\", \"experience\", \"current_job_years\", \"current_house_years\"]\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "H0 :- There is no relationship between categorical feature and target variable\\\n",
    "H1 :- There is some relationship between categorical feature and target variable\\\n",
    "If p-value â‰¥0.05, the null hypothesis is not rejected and there is no any relationship between target variable and categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://medium.com/analytics-vidhya/categorical-feature-selection-using-chi-squared-test-e4c0d0af6b7e\n",
    "# # https://towardsdatascience.com/using-the-chi-squared-test-for-feature-selection-with-implementation-b15a4dad93f1\n",
    "\n",
    "# # Standardisation gives negative values, chi-square does not allow negative values\n",
    "\n",
    "# chi_scores = chi2(x,y)\n",
    "# p_values = pd.Series(chi_scores[1],index = x.columns)\n",
    "# p_values.sort_values(ascending = False , inplace = True)\n",
    "# p_values.plot.bar()\n",
    "\n",
    "# # conclusion: current_house_years, profession_encoded, state_encoded have no relationship with target variable\n",
    "# x = x.drop([\"current_house_years\", \"profession_encoded\", \"state_encoded\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_loan = PCA()\n",
    "# x_train = pca_loan.fit_transform(x_train)\n",
    "# x_test = pca_loan.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"risk_flag\"]\n",
    "x = df.drop(\"risk_flag\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 2021,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing - Encoding categorical columns and scaling numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df_x, df_y):\n",
    "    \n",
    "    # Label encoding categorical columns with 2 types of categories\n",
    "    x = df_x.copy()\n",
    "    label_enc = LabelEncoder()\n",
    "    x[\"marital_status\"] = label_enc.fit_transform(x[\"marital_status\"])\n",
    "    x[\"car_ownership\"] = label_enc.fit_transform(x[\"car_ownership\"])\n",
    "    \n",
    "    # One Hot Encoding house_ownership column & Combining back to dataframe\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    \n",
    "    house_ownership_values = onehot_encoder.fit_transform( x[['house_ownership']] )\n",
    "    house_ownership_labels = np.array([\"norent_noown\", \"owned\", \"rented\"]).ravel()\n",
    "    house_ownership_df = pd.DataFrame(house_ownership_values, columns=house_ownership_labels)\n",
    "\n",
    "    x.reset_index(drop=True, inplace=True)\n",
    "    house_ownership_df.reset_index(drop=True, inplace=True)\n",
    "    x = pd.concat([ x, house_ownership_df], axis=1)\n",
    "    \n",
    "    x.drop(\"house_ownership\", axis=1, inplace=True)\n",
    "    \n",
    "    # Target Encoding the high cardinality categorical columns: profession, city, state\n",
    "    # https://medium.com/analytics-vidhya/target-encoding-vs-one-hot-encoding-with-simple-examples-276a7e7b3e64\n",
    "    profession_target_enc = TargetEncoder()\n",
    "    x[\"profession_encoded\"] = profession_target_enc.fit_transform(x[\"profession\"], df_y)\n",
    "    city_target_enc = TargetEncoder()\n",
    "    x[\"city_encoded\"] = city_target_enc.fit_transform(x[\"city\"], df_y)\n",
    "    state_target_enc = TargetEncoder()\n",
    "    x[\"state_encoded\"] = state_target_enc.fit_transform(x[\"state\"], df_y)\n",
    "    x.drop(\"profession\", axis=1, inplace=True)\n",
    "    x.drop(\"city\", axis=1, inplace=True)\n",
    "    x.drop(\"state\", axis=1, inplace=True)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler\n",
    "    # https://www.geeksforgeeks.org/standardscaler-minmaxscaler-and-robustscaler-techniques-ml/\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x[numerical_cols] = min_max_scaler.fit_transform(x[numerical_cols])\n",
    "    # need to scale the encoded columns?\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_preprocessing(x_train, y_train)\n",
    "x_test = data_preprocessing(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_variation_model(x_train, y_train, x_test, y_test, variation):\n",
    "    if \"pca\" in variation:\n",
    "        pca = PCA(0.9, random_state=2021)\n",
    "        x_train = pca.fit_transform(x_train)\n",
    "        x_test = pca.fit_transform(x_test)\n",
    "        \n",
    "    if \"chi_square\" in variation:\n",
    "        chi_scores = chi2(x_train, y_train)\n",
    "        p_values = pd.Series(chi_scores[1], index = x_train.columns)\n",
    "        p_values.sort_values(ascending = False , inplace = True)\n",
    "        p_values.plot.bar()\n",
    "        x_train = x_train.drop([\"profession_encoded\", \"state_encoded\", \"city_encoded\", \"income\"], axis=1)\n",
    "        x_test = x_test.drop([\"profession_encoded\", \"state_encoded\", \"city_encoded\", \"income\"], axis=1)\n",
    "        \n",
    "    if \"smote\" in variation:\n",
    "        oversampler = SMOTE(random_state=2021)\n",
    "        x_train, y_train = oversampler.fit_resample(x_train, y_train)\n",
    "        \n",
    "    classifier.fit(x_train, y_train)\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    \n",
    "    print(f\"-------------------------TEST SCORES for {variation}-----------------------\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"F2-Score: {fbeta_score(y_test, y_pred, beta=2)}\")\n",
    "    print(f\"Accuracy score: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying dtree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------TEST SCORES for base-----------------------\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "F2-Score: 0.0\n",
      "Accuracy score: 0.8770039682539682\n",
      "AUC Score: 0.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thine\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#dtree = tree.DecisionTreeClassifier(random_state=69)\n",
    "\n",
    "# dtree.fit(x_train, y_train)\n",
    "# x_test = data_preprocessing(x_test, y_test)\n",
    "# #x_test = pca_loan.fit_transform(x_test)\n",
    "# y_pred = dtree.predict(x_test)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "\n",
    "\n",
    "variations = [\"base\", \"smote\", \"chi_square\", \"pca\", \"smote, chi_square\", \"smote, pca\"]\n",
    "\n",
    "for variation in variations:\n",
    "    run_variation_model(x_train, y_train, x_test, y_test, variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "started at 2:18pm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
